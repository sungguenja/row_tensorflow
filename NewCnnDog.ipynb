{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 133 total dog categories.\n",
      "There are 8351 total dog images.\n",
      "\n",
      "There are 6680 training dog images.\n",
      "There are 835 validation dog images.\n",
      "There are 836 test dog images.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_files       \n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "def load_dataset(path):\n",
    "    data = load_files(path)\n",
    "    dog_files = np.array(data['filenames'])\n",
    "    dog_targets = np_utils.to_categorical(np.array(data['target']), 133)\n",
    "    return dog_files, dog_targets\n",
    "\n",
    "train_files, train_targets = load_dataset('dogs/train')\n",
    "valid_files, valid_targets = load_dataset('dogs/valid')\n",
    "test_files, test_targets = load_dataset('dogs/test')\n",
    "\n",
    "dog_names = [item[20:-1] for item in sorted(glob(\"dogs/train/*/\"))]\n",
    "\n",
    "# Let's check the dataset\n",
    "print('There are %d total dog categories.' % len(dog_names))\n",
    "print('There are %s total dog images.\\n' % len(np.hstack([train_files, valid_files, test_files])))\n",
    "print('There are %d training dog images.' % len(train_files))\n",
    "print('There are %d validation dog images.' % len(valid_files))\n",
    "print('There are %d test dog images.'% len(test_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image                  \n",
    "from tqdm import tqdm\n",
    "\n",
    "def path_to_tensor(img_path):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\n",
    "    x = image.img_to_array(img)\n",
    "    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "def paths_to_tensor(img_paths):\n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
    "    return np.vstack(list_of_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6680/6680 [00:47<00:00, 140.14it/s]\n",
      "100%|██████████| 835/835 [00:05<00:00, 157.35it/s]\n",
      "100%|██████████| 836/836 [00:05<00:00, 158.84it/s]\n"
     ]
    }
   ],
   "source": [
    "from PIL import ImageFile                            \n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True                 \n",
    "\n",
    "# pre-process the data for Keras\n",
    "train_tensors = paths_to_tensor(train_files).astype('float32')/255\n",
    "valid_tensors = paths_to_tensor(valid_files).astype('float32')/255\n",
    "test_tensors = paths_to_tensor(test_files).astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 224, 224, 16)      432       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 224, 224, 16)      48        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 224, 224, 16)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 56, 56, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 56, 56, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 56, 56, 32)        4608      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 56, 56, 32)        96        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 56, 56, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 64)        18432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 14, 14, 64)        192       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 128)         73728     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 4, 4, 128)         384       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 133)               68229     \n",
      "=================================================================\n",
      "Total params: 1,215,237\n",
      "Trainable params: 1,214,757\n",
      "Non-trainable params: 480\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout, Activation, Dense, Flatten\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16, (3, 3), padding='same', use_bias=False, input_shape=(224, 224, 3)))\n",
    "model.add(BatchNormalization(axis=3, scale=False))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(4, 4), strides=(4, 4), padding='same'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding='same', use_bias=False))\n",
    "model.add(BatchNormalization(axis=3, scale=False))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(4, 4), strides=(4, 4), padding='same'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same', use_bias=False))\n",
    "model.add(BatchNormalization(axis=3, scale=False))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(4, 4), strides=(4, 4), padding='same'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding='same', use_bias=False))\n",
    "model.add(BatchNormalization(axis=3, scale=False))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(133, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "209/209 [==============================] - ETA: 0s - loss: 4.8497 - accuracy: 0.0184\n",
      "Epoch 00001: val_loss improved from inf to 5.41804, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      "209/209 [==============================] - 53s 255ms/step - loss: 4.8497 - accuracy: 0.0184 - val_loss: 5.4180 - val_accuracy: 0.0108\n",
      "Epoch 2/10\n",
      "209/209 [==============================] - ETA: 0s - loss: 4.3895 - accuracy: 0.0458\n",
      "Epoch 00002: val_loss improved from 5.41804 to 4.87286, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      "209/209 [==============================] - 53s 254ms/step - loss: 4.3895 - accuracy: 0.0458 - val_loss: 4.8729 - val_accuracy: 0.0180\n",
      "Epoch 3/10\n",
      "209/209 [==============================] - ETA: 0s - loss: 4.1245 - accuracy: 0.0680\n",
      "Epoch 00003: val_loss did not improve from 4.87286\n",
      "209/209 [==============================] - 53s 255ms/step - loss: 4.1245 - accuracy: 0.0680 - val_loss: 5.2800 - val_accuracy: 0.0251\n",
      "Epoch 4/10\n",
      "209/209 [==============================] - ETA: 0s - loss: 3.9376 - accuracy: 0.0886\n",
      "Epoch 00004: val_loss improved from 4.87286 to 4.31580, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      "209/209 [==============================] - 53s 255ms/step - loss: 3.9376 - accuracy: 0.0886 - val_loss: 4.3158 - val_accuracy: 0.0683\n",
      "Epoch 5/10\n",
      "209/209 [==============================] - ETA: 0s - loss: 3.8051 - accuracy: 0.1057\n",
      "Epoch 00005: val_loss improved from 4.31580 to 4.03715, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      "209/209 [==============================] - 53s 255ms/step - loss: 3.8051 - accuracy: 0.1057 - val_loss: 4.0372 - val_accuracy: 0.0850\n",
      "Epoch 6/10\n",
      "209/209 [==============================] - ETA: 0s - loss: 3.6640 - accuracy: 0.1328\n",
      "Epoch 00006: val_loss improved from 4.03715 to 3.95896, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      "209/209 [==============================] - 54s 257ms/step - loss: 3.6640 - accuracy: 0.1328 - val_loss: 3.9590 - val_accuracy: 0.0874\n",
      "Epoch 7/10\n",
      "209/209 [==============================] - ETA: 0s - loss: 3.5433 - accuracy: 0.1403\n",
      "Epoch 00007: val_loss did not improve from 3.95896\n",
      "209/209 [==============================] - 53s 256ms/step - loss: 3.5433 - accuracy: 0.1403 - val_loss: 4.1801 - val_accuracy: 0.0958\n",
      "Epoch 8/10\n",
      "209/209 [==============================] - ETA: 0s - loss: 3.4693 - accuracy: 0.1599\n",
      "Epoch 00008: val_loss improved from 3.95896 to 3.84790, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      "209/209 [==============================] - 53s 255ms/step - loss: 3.4693 - accuracy: 0.1599 - val_loss: 3.8479 - val_accuracy: 0.1138\n",
      "Epoch 9/10\n",
      "209/209 [==============================] - ETA: 0s - loss: 3.3707 - accuracy: 0.1789\n",
      "Epoch 00009: val_loss did not improve from 3.84790\n",
      "209/209 [==============================] - 54s 256ms/step - loss: 3.3707 - accuracy: 0.1789 - val_loss: 4.9437 - val_accuracy: 0.0659\n",
      "Epoch 10/10\n",
      "209/209 [==============================] - ETA: 0s - loss: 3.2318 - accuracy: 0.2028\n",
      "Epoch 00010: val_loss did not improve from 3.84790\n",
      "209/209 [==============================] - 54s 257ms/step - loss: 3.2318 - accuracy: 0.2028 - val_loss: 5.1162 - val_accuracy: 0.0527\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f48c20d5950>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint  \n",
    "\n",
    "EPOCHS = 10\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.from_scratch.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "model.fit(train_tensors, train_targets, \n",
    "          validation_data=(valid_tensors, valid_targets),\n",
    "          epochs=EPOCHS, batch_size=32, callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 6.5789%\n"
     ]
    }
   ],
   "source": [
    "# get index of predicted dog breed for each image in test set\n",
    "dog_breed_predictions = [np.argmax(model.predict(np.expand_dims(tensor, axis=0))) for tensor in test_tensors]\n",
    "# report test accuracy\n",
    "test_accuracy = 100*np.sum(np.array(dog_breed_predictions)==np.argmax(test_targets, axis=1))/len(dog_breed_predictions)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.vgg19 import preprocess_input as preprocess_input_vgg19\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.resnet50 import preprocess_input as preprocess_input_resnet50\n",
    "\n",
    "def extract_VGG19(file_paths):\n",
    "    tensors = paths_to_tensor(file_paths).astype('float32')\n",
    "    preprocessed_input = preprocess_input_vgg19(tensors)\n",
    "    return VGG19(weights='imagenet', include_top=False).predict(preprocessed_input, batch_size=32)\n",
    "\n",
    "def extract_Resnet50(file_paths):\n",
    "    tensors = paths_to_tensor(file_paths).astype('float32')\n",
    "    preprocessed_input = preprocess_input_resnet50(tensors)\n",
    "    return ResNet50(weights='imagenet', include_top=False).predict(preprocessed_input, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6680/6680 [00:47<00:00, 142.07it/s]\n",
      "100%|██████████| 835/835 [00:05<00:00, 157.02it/s]\n",
      "100%|██████████| 836/836 [00:05<00:00, 158.44it/s]\n",
      "  0%|          | 25/6680 [00:00<00:27, 244.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG19 shape (7, 7, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6680/6680 [00:47<00:00, 141.48it/s]\n",
      "100%|██████████| 835/835 [00:05<00:00, 155.38it/s]\n",
      "100%|██████████| 836/836 [00:05<00:00, 158.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resnet50 shape (7, 7, 2048)\n"
     ]
    }
   ],
   "source": [
    "train_vgg19 = extract_VGG19(train_files)\n",
    "valid_vgg19 = extract_VGG19(valid_files)\n",
    "test_vgg19 = extract_VGG19(test_files)\n",
    "print(\"VGG19 shape\", train_vgg19.shape[1:])\n",
    "\n",
    "train_resnet50 = extract_Resnet50(train_files)\n",
    "valid_resnet50 = extract_Resnet50(valid_files)\n",
    "test_resnet50 = extract_Resnet50(test_files)\n",
    "print(\"Resnet50 shape\", train_resnet50.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            [(None, 7, 7, 512)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            [(None, 1, 1, 2048)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 512)          0           input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2048)         0           input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          65536       global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 512)          1048576     global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 128)          512         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 512)          2048        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 128)          0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 512)          0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 640)          0           activation_4[0][0]               \n",
      "                                                                 activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 640)          0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 640)          409600      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 640)          2560        dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 640)          0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 640)          0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 133)          85253       dropout_5[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,614,085\n",
      "Trainable params: 1,611,525\n",
      "Non-trainable params: 2,560\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.layers.pooling import GlobalAveragePooling2D\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers import Input, Dense\n",
    "from keras.layers.core import Dropout, Activation\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "\n",
    "def input_branch(input_shape=None):\n",
    "    \n",
    "    size = int(input_shape[2] / 4)\n",
    "    \n",
    "    branch_input = Input(shape=input_shape)\n",
    "    branch = GlobalAveragePooling2D()(branch_input)\n",
    "    branch = Dense(size, use_bias=False, kernel_initializer='uniform')(branch)\n",
    "    branch = BatchNormalization()(branch)\n",
    "    branch = Activation(\"relu\")(branch)\n",
    "    return branch, branch_input\n",
    "\n",
    "vgg19_branch, vgg19_input = input_branch(input_shape=(7, 7, 512))\n",
    "resnet50_branch, resnet50_input = input_branch(input_shape=(1, 1, 2048))\n",
    "concatenate_branches = Concatenate()([vgg19_branch, resnet50_branch])\n",
    "net = Dropout(0.3)(concatenate_branches)\n",
    "net = Dense(640, use_bias=False, kernel_initializer='uniform')(net)\n",
    "net = BatchNormalization()(net)\n",
    "net = Activation(\"relu\")(net)\n",
    "net = Dropout(0.3)(net)\n",
    "net = Dense(133, kernel_initializer='uniform', activation=\"softmax\")(net)\n",
    "\n",
    "model = Model(inputs=[vgg19_input, resnet50_input], outputs=[net])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1, 2048) for input Tensor(\"input_8:0\", shape=(None, 1, 1, 2048), dtype=float32), but it was called on an input with incompatible shape (4, 7, 7, 2048).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1, 2048) for input Tensor(\"input_8:0\", shape=(None, 1, 1, 2048), dtype=float32), but it was called on an input with incompatible shape (4, 7, 7, 2048).\n",
      "1665/1670 [============================>.] - ETA: 0s - loss: 2.6659 - accuracy: 0.3592WARNING:tensorflow:Model was constructed with shape (None, 1, 1, 2048) for input Tensor(\"input_8:0\", shape=(None, 1, 1, 2048), dtype=float32), but it was called on an input with incompatible shape (None, 7, 7, 2048).\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.95433, saving model to saved_models/bestmodel.hdf5\n",
      "1670/1670 [==============================] - 7s 4ms/step - loss: 2.6644 - accuracy: 0.3597 - val_loss: 0.9543 - val_accuracy: 0.7114\n",
      "Epoch 2/10\n",
      "1664/1670 [============================>.] - ETA: 0s - loss: 1.5450 - accuracy: 0.5666\n",
      "Epoch 00002: val_loss improved from 0.95433 to 0.82596, saving model to saved_models/bestmodel.hdf5\n",
      "1670/1670 [==============================] - 7s 4ms/step - loss: 1.5468 - accuracy: 0.5662 - val_loss: 0.8260 - val_accuracy: 0.7617\n",
      "Epoch 3/10\n",
      "1664/1670 [============================>.] - ETA: 0s - loss: 1.3343 - accuracy: 0.6206\n",
      "Epoch 00003: val_loss improved from 0.82596 to 0.79415, saving model to saved_models/bestmodel.hdf5\n",
      "1670/1670 [==============================] - 7s 4ms/step - loss: 1.3328 - accuracy: 0.6211 - val_loss: 0.7941 - val_accuracy: 0.7725\n",
      "Epoch 4/10\n",
      "1665/1670 [============================>.] - ETA: 0s - loss: 1.2362 - accuracy: 0.6577\n",
      "Epoch 00004: val_loss improved from 0.79415 to 0.76536, saving model to saved_models/bestmodel.hdf5\n",
      "1670/1670 [==============================] - 7s 4ms/step - loss: 1.2373 - accuracy: 0.6576 - val_loss: 0.7654 - val_accuracy: 0.7772\n",
      "Epoch 5/10\n",
      "1665/1670 [============================>.] - ETA: 0s - loss: 1.1244 - accuracy: 0.6896\n",
      "Epoch 00005: val_loss did not improve from 0.76536\n",
      "1670/1670 [==============================] - 7s 4ms/step - loss: 1.1246 - accuracy: 0.6895 - val_loss: 0.8195 - val_accuracy: 0.7904\n",
      "Epoch 6/10\n",
      "1665/1670 [============================>.] - ETA: 0s - loss: 1.0480 - accuracy: 0.7116\n",
      "Epoch 00006: val_loss improved from 0.76536 to 0.70563, saving model to saved_models/bestmodel.hdf5\n",
      "1670/1670 [==============================] - 7s 4ms/step - loss: 1.0487 - accuracy: 0.7115 - val_loss: 0.7056 - val_accuracy: 0.8048\n",
      "Epoch 7/10\n",
      "1665/1670 [============================>.] - ETA: 0s - loss: 0.9957 - accuracy: 0.7242\n",
      "Epoch 00007: val_loss improved from 0.70563 to 0.67025, saving model to saved_models/bestmodel.hdf5\n",
      "1670/1670 [==============================] - 7s 4ms/step - loss: 0.9966 - accuracy: 0.7241 - val_loss: 0.6702 - val_accuracy: 0.8168\n",
      "Epoch 8/10\n",
      "1665/1670 [============================>.] - ETA: 0s - loss: 0.9541 - accuracy: 0.7279\n",
      "Epoch 00008: val_loss did not improve from 0.67025\n",
      "1670/1670 [==============================] - 7s 4ms/step - loss: 0.9548 - accuracy: 0.7278 - val_loss: 0.7567 - val_accuracy: 0.7964\n",
      "Epoch 9/10\n",
      "1665/1670 [============================>.] - ETA: 0s - loss: 0.9225 - accuracy: 0.7434\n",
      "Epoch 00009: val_loss did not improve from 0.67025\n",
      "1670/1670 [==============================] - 7s 4ms/step - loss: 0.9220 - accuracy: 0.7431 - val_loss: 0.7008 - val_accuracy: 0.8096\n",
      "Epoch 10/10\n",
      "1665/1670 [============================>.] - ETA: 0s - loss: 0.8929 - accuracy: 0.7458\n",
      "Epoch 00010: val_loss did not improve from 0.67025\n",
      "1670/1670 [==============================] - 7s 4ms/step - loss: 0.8931 - accuracy: 0.7458 - val_loss: 0.7305 - val_accuracy: 0.8120\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4819571c90>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=\"rmsprop\", metrics=['accuracy'])\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/bestmodel.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "model.fit([train_vgg19, train_resnet50], train_targets, \n",
    "          validation_data=([valid_vgg19, valid_resnet50], valid_targets),\n",
    "          epochs=10, batch_size=4, callbacks=[checkpointer], verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1, 2048) for input Tensor(\"input_8:0\", shape=(None, 1, 1, 2048), dtype=float32), but it was called on an input with incompatible shape (None, 7, 7, 2048).\n",
      "Test accuracy: 79.7847%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "predictions = model.predict([test_vgg19, test_resnet50])\n",
    "breed_predictions = [np.argmax(prediction) for prediction in predictions]\n",
    "breed_true_labels = [np.argmax(true_label) for true_label in test_targets]\n",
    "print('Test accuracy: %.4f%%' % (accuracy_score(breed_true_labels, breed_predictions) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 464.28it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 469.74it/s]\n"
     ]
    }
   ],
   "source": [
    "predic = model.predict([extract_VGG19(['dogs/test/027.Bloodhound/Bloodhound_01871.jpg']),extract_Resnet50(['dogs/test/027.Bloodhound/Bloodhound_01871.jpg'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax(predic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-94f4d0760acc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'CNN_dog_breed_model_v2.json'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mjson_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'CNN_dog_breed_model_v2.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model_json = model.to_json()\n",
    "with open('CNN_dog_breed_model_v2.json','w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "model.save_weights('CNN_dog_breed_model_v2.h5')\n",
    "print('Saved model to disk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog = {0:'아펜핀셔',1:'아프간 하운드',2:'에어데일 테리어',3:'아키타견',4:'알레스칸 말라뮤트',\n",
    "      5:'아메리칸 에스키모',6:''}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 종 분류 모델 가져오기\n",
    "from tensorflow.compat.v2.keras.models import model_from_json\n",
    "\n",
    "# json 파일 열기-v2\n",
    "json_file = open('CNN_dog_breed_model_v2.json','r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "\n",
    "# json 파일로부터 model 로드하기\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "# 로드한 model에 weight 로드하기\n",
    "loaded_model.load_weights('CNN_dog_breed_model_v2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 196.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:8 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f18e27f9950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 193.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:9 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f18b338ca70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "predic = loaded_model.predict([extract_VGG19(['cats/american_bulldog_29.jpg']),extract_Resnet50(['cats/american_bulldog_29.jpg'])])\n",
    "print(np.argmax(predic))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
